import streamlit as st
import librosa
import numpy as np
import tensorflow as tf
import pickle
from PIL import Image
import tempfile

# --- Load model and label encoder ---
model = tf.keras.models.load_model('models/tamil_slang_model.h5')
with open('models/label_encoder.pkl', 'rb') as f:
    label_encoder = pickle.load(f)

# --- Page config ---
st.set_page_config(
    page_title="роХрпБро░ро▓рпНро╡ро╛рогро┐ AI - Tamil Dialect Detection",
    page_icon="assets/tamillogo.jpeg",
    layout="centered",
    initial_sidebar_state="collapsed",
)

# --- CSS styling ---
st.markdown(
    """
    <style>
    body {
        background-color: #f9f6f2;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .title {
        font-size: 3rem;
        font-weight: 800;
        color: #6b2c2c;
        margin-bottom: 0.1rem;
        text-align: center;
    }
    .subtitle {
        font-size: 1.3rem;
        color: #a34444;
        margin-top: 0;
        margin-bottom: 2rem;
        text-align: center;
    }
    .stButton>button {
        background-color: #a34444;
        color: white;
        font-weight: 600;
        border-radius: 8px;
        padding: 0.6rem 2rem;
        transition: background-color 0.3s ease;
        display: block;
        margin: 0 auto;
    }
    .stButton>button:hover {
        background-color: #7f2a2a;
        cursor: pointer;
    }
    .confidence {
        font-weight: 700;
        color: #4b403f;
        font-size: 1.1rem;
        margin-top: 1rem;
        text-align: center;
    }
    .result {
        text-align: center;
        font-size: 1.4rem;
        font-weight: 700;
        color: #5a2b2b;
    }
    .gif-container {
        text-align: center;
        margin: 1rem 0;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# --- Logo ---
logo = Image.open('assets/tamillogo.jpeg')
st.image(logo, width=120)

# --- Title and subtitles ---
st.markdown('<h1 class="title">роХрпБро░ро▓рпНро╡ро╛рогро┐ AI - родрооро┐ро┤рпН ро╡роЯрпНроЯро╛ро░ ро╡ро┤роХрпНроХрпБ роХрогрпНроЯро▒ро┐родро▓рпН</h1>', unsafe_allow_html=True)
st.markdown('<h3 class="subtitle">KuralVani AI - Tamil Dialect Detection</h3>', unsafe_allow_html=True)
st.write("**родрооро┐ро┤рпН рокрпЗроЪрпБроорпН роЗроЯроорпН роОроЩрпНроХрпЗ роОройрпНро▒рпБ роЗроирпНрод роЖроЯро┐ропрпЛро╡ро╛ро▓рпН роХрогрпНроЯро▒ро┐ропрпБроЩрпНроХро│рпН.**")
st.write("**Detect the regional Tamil dialect from this audio.**")
st.write("---")

# --- File uploader ---
audio_file = st.file_uploader(
    "ЁЯОд роЙроЩрпНроХро│рпН родрооро┐ро┤рпН ро╡роЯрпНроЯро╛ро░ роЖроЯро┐ропрпЛро╡рпИ рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН (Upload your Tamil dialect audio file)",
    type=['wav', 'mp3']
)

# --- MFCC extraction ---
def extract_mfcc(file):
    y, sr = librosa.load(file, sr=22050)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    if mfcc.shape[1] < 40:
        pad_width = 40 - mfcc.shape[1]
        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')
    else:
        mfcc = mfcc[:, :40]
    mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)
    mfcc = mfcc.reshape(1, 40, 40, 1).astype(np.float32)
    return mfcc

# --- Dialect label mapping ---
dialect_map = {
    'chennai': 'роЪрпЖройрпНройрпИ (Chennai)',
    'madurai': 'роородрпБро░рпИ (Madurai)',
    'tirunelveli': 'родро┐ро░рпБроирпЖро▓рпНро╡рпЗро▓ро┐ (Tirunelveli)',
    'srilanka': 'роЗро▓роЩрпНроХрпИ (Sri Lanka)',
    'standard': 'ро╕рпНроЯро╛ройрпНроЯро░рпНроЯрпБ родрооро┐ро┤рпН (Standard Tamil)'
}

# --- Main Prediction Block ---
if audio_file is not None:
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(audio_file.read())
        tmp_path = tmp.name

    with st.spinner("ЁЯФН роХрогро┐рокрпНрокро┐роХрпНроХро┐ро▒родрпБ... / Computing prediction..."):
        st.markdown(
            '<div class="gif-container">'
            '<img src="assets/waveform.gif" width="120" alt="waveform gif"/>'
            '</div>', 
            unsafe_allow_html=True
        )

        try:
            mfcc_input = extract_mfcc(tmp_path)
            prediction = model.predict(mfcc_input)
            pred_index = np.argmax(prediction)
            pred_label = label_encoder.inverse_transform([pred_index])[0]
            confidence = prediction[0][pred_index] * 100
            pred_label_tamil = dialect_map.get(pred_label.lower(), pred_label)

            st.markdown(f'<p class="result">ро╡роЯрпНроЯро╛ро░ ро╡ро┤роХрпНроХрпБ: {pred_label_tamil} / Dialect: {pred_label_tamil}</p>', unsafe_allow_html=True)
            st.markdown(f'<p class="confidence">роироорпНрокро┐роХрпНроХрпИ / Confidence: {confidence:.2f}%</p>', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"тЪая╕П рокро┐ро┤рпИ роПро▒рпНрокроЯрпНроЯродрпБ: {str(e)}")

# --- Footer ---
st.markdown("---")
st.write("**Developed by KuralVani AI Team** | ┬й 2025")
